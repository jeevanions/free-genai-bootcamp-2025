As an experience web developer created a frontend application that helps 

Give me (please) vocabulary language importer where we have a text field that allows us to import a thematic category for the generation of language vocabulary.
When submitting that text field, it should hit an api endpoint (api route in app router) to invoke an LLM chat completions in Groq (LLM) on the server-side and then pass that information back to the front-end
It has to create a structured json output like this example:

```json
{
      "italian": "ciao",
      "english": "hello",
      "parts": {
        "type": "interjection",
        "informal": true,
        "usage": ["greeting", "farewell"]
      }
}
```

The json that is outputted back to the front-end should be copy-able... so it should be sent to an input field and there should be a copy button so that it can be copied to the clipboard and that should give an alert that it was copied to the user's clipboard.
The app should use app router and the latest version of next.js.. and the lim calls should run in an api route on the server-side.



Give me (please) vocabulary language importer where we have a text field that allows us to import a thematic category for the generation of language vocabulary.
When submitting that text field, it should hit an api endpoint (api route in app router) to invoke an LLM chat completions in Groq (LLM) on the server-side and then pass that information back to the front-end
It has to create a structured json output like this example:

The json that is outputted back to the front-end should be copy-able... so it should be sent to an input field and there should be a copy button so that it can be copied to the clipboard and that should give an alert that it was copied to the user's clipboard.

# Backend changes

Add below endpoint for getting Italian words based on the given thematic category. This endpoint will call LLM models in Groq to generate Italian words based on the given thematic category. These words will be sent to the front-end as a json response where use will validate it and make any correction needed and finally submit it to add it to our database.
The response from LLM should be in json format with list of words where each word should be in this format
```
{
      "italian": "sorella",
      "english": "sister",
      "parts": {
        "type": "noun",
        "gender": "feminine",
        "plural": "sorelle"
      }
}
```

Second endpoint is for when user verifies the list of words for the group (generated by LLM) would be submitted from the UI. While submitting group name with list of words in json format should be sent to backend.
In backend first we check if the group already exists if exists use the group id or insert new group in the `groups` table. Then insert the words in the `words` table. Get the word ids just instered and insert the word to group relationship in the `words_groups` table. Finally return the group id. 



Go through exising code base and @backend-tech-spec.md to understand the pattern, design and libraries & tools used. 
Additional endpoints needed for feature details below

We are going to build a new frontend application named "Vocab Importer" which will be used to generate new vocabulary for a given thematic category(group).
In the frontend we will have 4 UI components 
1. list[pre-populated with a list of group name in the system] - If user wants to add they could add new group name by typing in the input field and hit enter. This should fire an endpoint "POST /api/groups" to add new group name in the database. I think group name should passed as query param. Response should be the group id.
2. Next is a button "Generate" which will call an endpoint "POST /api/words/generate" with group name as query param. This endpoint will call LLM models in Groq to generate Italian words based on the given thematic category. These words will be sent to the front-end as a json response 
3. The above response will be displayed in the multi line text area for the user to validate it and make any correction needed.
4. A button to import the words in the database. This will call an endpoint "POST /api/words/import" with group name & Id and list of words in json format.
5. The LLM resoponse should generate list of words in below format
   ```
{
      "italian": "sorella",
      "english": "sister",
      "parts": {
        "type": "noun",
        "gender": "feminine",
        "plural": "sorelle"
      }
}
```
1. We are going to use LLM models in groq to generate the words. So search internet to find the most used and popular library for groq and use it in the backend.
2. List all the new endpoints that will be created. And add these in the right section of the @backend-tech-spec.md. There is already some implementation in the backend so review that and update as necessary.
3. Add swagger docs for the new endpoints.

   
   
Then do "Add below endpoint for getting Italian words based on the given thematic category. This endpoint will call LLM models in Groq to generate Italian words based on the given thematic category. These words will be sent to the front-end as a json response where use will validate it and make any correction needed and finally submit it to add it to our database.
The response from LLM should be in json format with list of words where each word should be in this format


Second endpoint is for when user verifies the list of words for the group (generated by LLM) would be submitted from the UI. While submitting group name with list of words in json format should be sent to backend.
In backend first we check if the group already exists if exists use the group id or insert new group in the `groups` table. Then insert the words in the `words` table. Get the word ids just instered and insert the word to group relationship in the `words_groups` table. Finally return the group id. " Add swagger docs, updaet @backend-tech-spec.md spec 